<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>RGB-D相机 - FangjieYu‘s site</title><meta name=Description content="This is my cool site"><meta property="og:url" content="https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/">
<meta property="og:site_name" content="FangjieYu‘s site"><meta property="og:title" content="RGB-D相机"><meta property="og:description" content="基本原理 深度相机生成深度图，深度图是图像中每个像素点的深度值，通常以毫米为单位。它通过测量光线从相机到物体表面的距离，再返回相机的时间或相位差，计算出每个像素的深度信息。"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-03T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-29T00:00:00+00:00"><meta property="article:tag" content="RGBD"><meta property="article:tag" content="传感器"><meta property="article:tag" content="硬件"><meta property="article:tag" content="3d"><meta name=twitter:card content="summary"><meta name=twitter:title content="RGB-D相机"><meta name=twitter:description content="基本原理 深度相机生成深度图，深度图是图像中每个像素点的深度值，通常以毫米为单位。它通过测量光线从相机到物体表面的距离，再返回相机的时间或相位差，计算出每个像素的深度信息。"><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/><link rel=prev href=https://fjyu95.github.io/posts/dust3r-series-15ee4020f0608006803bfe528b97cab2/><link rel=next href=https://fjyu95.github.io/posts/ros-17ae4020f0608037ab9ce65eddd62e49/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"RGB-D相机","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/fjyu95.github.io\/posts\/rgb-d-cam-170e4020f06080198bd5cb4e98e89580\/"},"genre":"posts","keywords":"RGBD, 传感器, 硬件, 3d","wordcount":3642,"url":"https:\/\/fjyu95.github.io\/posts\/rgb-d-cam-170e4020f06080198bd5cb4e98e89580\/","datePublished":"2025-01-03T00:00:00+00:00","dateModified":"2025-04-29T00:00:00+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"fjyu95"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="FangjieYu‘s site">fjyu95</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>posts </a><a class=menu-item href=/tags/>tags </a><a class=menu-item href=/categories/>category </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="FangjieYu‘s site">fjyu95</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>posts</a><a class=menu-item href=/tags/ title>tags</a><a class=menu-item href=/categories/ title>category</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">RGB-D相机</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://fjyu95.github.io/ title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>fjyu95</a></span>&nbsp;<span class=post-category>included in <a href=/categories/%E7%A1%AC%E4%BB%B6%E7%AC%94%E8%AE%B0/><i class="far fa-folder fa-fw" aria-hidden=true></i>硬件笔记</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2025-01-03>2025-01-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;3642 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;8 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#基本原理>基本原理</a><ul><li><a href=#接近传感器>接近传感器</a></li></ul></li><li><a href=#型号>型号</a></li><li><a href=#tof-vs-lidar>ToF v.s. Lidar</a><ul><li><ul><li><a href=#1-基本原理><strong>1. 基本原理</strong></a></li><li><a href=#tof时间飞行><strong>ToF（时间飞行）</strong></a></li><li><a href=#激光雷达lidar><strong>激光雷达（LiDAR）</strong></a></li><li><a href=#2-数据输出形式><strong>2. 数据输出形式</strong></a></li><li><a href=#tof><strong>ToF</strong>:</a></li><li><a href=#lidar><strong>LiDAR</strong>:</a></li><li><a href=#3-技术特点对比><strong>3. 技术特点对比</strong></a></li><li><a href=#关键差异总结><strong>关键差异总结</strong></a></li><li><a href=#选择依据><strong>选择依据</strong></a></li></ul></li></ul></li><li><a href=#数据配准>数据配准</a><ul><li><ul><li><a href=#标定目标><strong>标定目标</strong></a></li><li><a href=#标定的步骤><strong>标定的步骤</strong></a></li><li><a href=#1-准备工具和环境><strong>1. 准备工具和环境</strong></a></li><li><a href=#2-采集标定数据><strong>2. 采集标定数据</strong></a></li><li><a href=#3-标定过程><strong>3. 标定过程</strong></a></li><li><a href=#1rgb-相机内参标定><strong>（1）RGB 相机内参标定</strong></a></li><li><a href=#2深度相机内参标定><strong>（2）深度相机内参标定</strong></a></li><li><a href=#3外参标定><strong>（3）外参标定</strong></a></li><li><a href=#4验证标定结果><strong>（4）验证标定结果</strong></a></li></ul></li><li><a href=#接收器-or-发射器>接收器 or 发射器</a><ul><li><a href=#外参标定与接收器的关系><strong>外参标定与接收器的关系</strong></a></li><li><a href=#为什么发射器不参与外参标定><strong>为什么发射器不参与外参标定？</strong></a></li></ul></li></ul></li><li><a href=#准确性>准确性</a></li><li><a href=#常见问题>常见问题</a><ul><li><a href=#缺失值nan>缺失值nan</a><ul><li><a href=#1-透明或高反射物体><strong>1. 透明或高反射物体</strong></a></li><li><a href=#原因><strong>原因：</strong></a></li><li><a href=#表现><strong>表现：</strong></a></li><li><a href=#2-测量范围限制><strong>2. 测量范围限制</strong></a></li><li><a href=#原因-1><strong>原因：</strong></a></li><li><a href=#表现-1><strong>表现：</strong></a></li><li><a href=#3-采集环境中的干扰><strong>3. 采集环境中的干扰</strong></a></li><li><a href=#原因-2><strong>原因：</strong></a></li><li><a href=#表现-2><strong>表现：</strong></a></li><li><a href=#4-视角问题和遮挡><strong>4. 视角问题和遮挡</strong></a></li><li><a href=#原因-3><strong>原因：</strong></a></li><li><a href=#表现-3><strong>表现：</strong></a></li><li><a href=#5-数据插值或重建失败><strong>5. 数据插值或重建失败</strong></a></li><li><a href=#原因-4><strong>原因：</strong></a></li><li><a href=#表现-4><strong>表现：</strong></a></li><li><a href=#6-软件或硬件问题><strong>6. 软件或硬件问题</strong></a></li><li><a href=#原因-5><strong>原因：</strong></a></li><li><a href=#表现-5><strong>表现：</strong></a></li><li><a href=#7-校准误差><strong>7. 校准误差</strong></a></li><li><a href=#原因-6><strong>原因：</strong></a></li><li><a href=#表现-6><strong>表现：</strong></a></li></ul></li></ul></li></ul></nav></div></div><div class=content id=content><h1 id=基本原理>基本原理</h1><p>深度相机生成深度图，深度图是图像中每个像素点的深度值，<strong>通常以毫米为单位</strong>。它通过测量光线从相机到物体表面的距离，再<strong>返回相机的时间或相位差</strong>，计算出每个像素的深度信息。</p><p>通常，RGB-D 相机由以下组件构成：</p><ol><li><strong>RGB 相机</strong>：捕捉彩色图像。</li><li><strong>红外投影器（IR Emitter）</strong>：<strong>发射红外光</strong>（通常为点阵、光栅或结构光）。</li><li><strong>红外相机（IR Camera）</strong>：<strong>捕捉</strong>由投影器发出的红外光反射信号。</li><li><strong>计算单元</strong>：结合 RGB 和 IR 数据计算深度图。</li></ol><h2 id=接近传感器>接近传感器</h2><p>深度相机中的接近传感器主要用于检测物体与相机的距离，提供粗略的距离信息或触发相机的工作流程。它是一种重要的辅助设备，但无法替代深度相机的核心功能（如生成高分辨率的深度图）。在使用过程中，可以根据具体需求选择合适的接近传感器类型，实现优化与集成。</p><ul><li><strong>距离检测</strong><ul><li>接近传感器可以快速检测物体是否进入相机的工作范围，并提供粗略的距离测量。</li><li>常用于：<ul><li>触发深度采集过程（节能或优化工作流程）。</li><li>判断物体是否在相机的有效测量范围内。</li></ul></li></ul></li><li><strong>范围优化</strong><ul><li>检测物体是否超出深度相机的测量范围（例如太近或太远）。</li><li>在近距离（如小于相机的最小工作距离）或远距离（超出测量上限）时，深度数据可能出现错误或不可靠，接近传感器可以提前识别并发出警告。</li></ul></li><li><strong>辅助对焦或视场调整</strong><ul><li>某些深度相机通过接近传感器来优化光学或红外投影的焦点设置，提升数据质量。</li></ul></li><li><strong>环境感知</strong><ul><li>在非成像任务中（如机器人避障、自动门控制），接近传感器可以作为一种快速响应机制，触发更复杂的深度感知或其他设备操作。</li></ul></li></ul><h1 id=型号>型号</h1><p>kinect</p><p>realsense</p><p>奥比中光</p><p>光鉴</p><h1 id=tof-vs-lidar>ToF v.s. Lidar</h1><p>**ToF（Time-of-Flight）和激光雷达（LiDAR）**都是基于时间飞行原理的测距技术，用于获取物体与传感器之间的距离。尽管二者共享相似的基本原理，但它们的具体实现方式、适用场景和硬件架构有显著区别。</p><h3 id=1-基本原理><strong>1. 基本原理</strong></h3><h3 id=tof时间飞行><strong>ToF（时间飞行）</strong></h3><ul><li><p><strong>原理</strong>：通过测量光脉冲从发射到返回的时间差，计算物体的距离。公式为：<br>d=2c⋅t​<br>其中 c 为光速，t 为光脉冲的飞行时间。</p><p>d=c⋅t2d = \frac{c \cdot t}{2}</p></li><li><p><strong>实现方式</strong>：</p><ul><li>使用调制光源（如红外光或激光）和光电探测器。</li><li>通常采用面阵传感器（如 CMOS 或 CCD）捕获深度图。</li></ul></li></ul><h3 id=激光雷达lidar><strong>激光雷达（LiDAR）</strong></h3><ul><li><strong>原理</strong>：同样基于时间飞行，但多采用高能量、窄束的激光进行测量。</li><li><strong>实现方式</strong>：<ul><li>发射单点激光或激光束，并通过机械或电子方式扫描区域。</li><li>激光点的反射信号由接收器捕获，测量距离。</li><li>输出的是点云数据。</li></ul></li></ul><hr><h3 id=2-数据输出形式><strong>2. 数据输出形式</strong></h3><h3 id=tof><strong>ToF</strong>:</h3><ul><li><strong>深度图</strong>：<ul><li>每个像素点对应一个深度值（二维平面上的密集深度信息）。</li><li>适合需要高分辨率的场景。</li></ul></li><li><strong>RGB-D 数据</strong>：<ul><li>可以将深度图与 RGB 图像结合，生成彩色的三维信息。</li></ul></li></ul><h3 id=lidar><strong>LiDAR</strong>:</h3><ul><li><strong>点云</strong>：<ul><li><p>输出的是稀疏的三维点云。</p></li><li><p>每个点有三维坐标 (x,y,z) 和可能的强度值（反射率）。</p><p>x,y,zx, y, z</p></li><li><p>适合大范围、高精度的三维场景重建。</p></li></ul></li></ul><hr><h3 id=3-技术特点对比><strong>3. 技术特点对比</strong></h3><table><thead><tr><th>特性</th><th>ToF</th><th>激光雷达（LiDAR）</th></tr></thead><tbody><tr><td><strong>光源</strong></td><td>红外光（LED/激光）</td><td>激光（常为 905 nm 或 1550 nm）</td></tr><tr><td><strong>检测方式</strong></td><td>面阵检测（二维传感器）</td><td>单点或线扫描</td></tr><tr><td><strong>输出数据</strong></td><td>深度图（密集）</td><td>点云（稀疏）</td></tr><tr><td><strong>测量范围</strong></td><td>一般 0.1-10 米，适合近距离</td><td>通常可达数十米到数百米</td></tr><tr><td><strong>精度</strong></td><td>准确性较高（毫米级）</td><td>高精度（毫米到厘米级）</td></tr><tr><td><strong>分辨率</strong></td><td>高分辨率（与传感器像素数有关）</td><td>较低（取决于扫描点数）</td></tr><tr><td><strong>视场（FOV）</strong></td><td>广视场（通常 > 60°）</td><td>可调（通常视场较窄）</td></tr><tr><td><strong>移动部件</strong></td><td>无移动部件</td><td>有（机械 LiDAR）或无（固态 LiDAR）</td></tr><tr><td><strong>成本</strong></td><td>较低</td><td>较高</td></tr></tbody></table><h3 id=关键差异总结><strong>关键差异总结</strong></h3><ol><li><strong>分辨率与数据密度</strong>：<ul><li>ToF 提供的是高分辨率深度图，适合近距离且需要高密度数据的场景。</li><li>LiDAR 输出稀疏点云，适合远距离测量和大范围场景。</li></ul></li><li><strong>测量范围</strong>：<ul><li>ToF 通常用于近距离测量。</li><li>LiDAR 可实现几十米甚至更远的距离测量。</li></ul></li><li><strong>硬件复杂度</strong>：<ul><li>ToF 通常没有机械运动部件，结构简单。</li><li>LiDAR 可能包含机械旋转部件，或者使用更复杂的 MEMS 或光栅扫描技术。</li></ul></li><li><strong>成本</strong>：<ul><li>ToF 的成本较低，适合消费级设备。</li><li>LiDAR 成本较高，多用于工业和高端应用。</li></ul></li></ol><hr><h3 id=选择依据><strong>选择依据</strong></h3><ul><li>如果需要<strong>近距离检测</strong>且注重<strong>分辨率</strong>（如手势识别、工业检测）：选择 <strong>ToF</strong>。</li><li>如果需要<strong>远距离测量</strong>且注重<strong>场景精确建模</strong>（如自动驾驶、测绘）：选择 <strong>LiDAR</strong>。</li></ul><h1 id=数据配准>数据配准</h1><p><strong>深度相机与RGB 相机通常需要进行外参标定</strong></p><p>RGB-D 相机的外参标定是指对 RGB 相机与深度相机之间的位置关系（即旋转矩阵和平移向量）进行标定。这是实现 RGB 图像与深度图像对齐（或融合）的关键步骤。通过外参标定，可以将深度图中的点投影到 RGB 图像上，或者反过来，将 RGB 图像的像素对应到三维空间中。</p><h3 id=标定目标><strong>标定目标</strong></h3><p>标定的主要目的是获取以下外参：</p><ol><li><strong>旋转矩阵 R</strong>：描述 RGB 相机和深度相机的坐标系之间的旋转关系。</li><li><strong>平移向量 T</strong>：描述 RGB 相机和深度相机坐标系的平移关系。</li></ol><p>最终，外参描述为：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=RGB-D%20Cam%20170e4020f06080198bd5cb4e98e89580/image.png data-srcset="RGB-D%20Cam%20170e4020f06080198bd5cb4e98e89580/image.png, RGB-D%20Cam%20170e4020f06080198bd5cb4e98e89580/image.png 1.5x, RGB-D%20Cam%20170e4020f06080198bd5cb4e98e89580/image.png 2x" data-sizes=auto alt=RGB-D%20Cam%20170e4020f06080198bd5cb4e98e89580/image.png title=image.png></p><h3 id=标定的步骤><strong>标定的步骤</strong></h3><h3 id=1-准备工具和环境><strong>1. 准备工具和环境</strong></h3><ul><li><strong>标定板</strong>：常用的是棋盘格或圆点阵列标定板（黑白对比明显）。</li><li><strong>标定工具</strong>：如 <code>OpenCV</code> 的标定模块、<code>ROS</code> 的标定包（如 <code>camera_calibration</code> 或 <code>rgbd_calibration</code>）。</li><li><strong>稳定环境</strong>：避免相机或标定板的晃动，确保拍摄过程中的数据质量。</li></ul><hr><h3 id=2-采集标定数据><strong>2. 采集标定数据</strong></h3><ul><li><strong>目标</strong>：同时获取 RGB 图像和深度图像中标定板的清晰视图。</li><li>将标定板放置在相机视场范围内，并采集多组数据（一般建议 10-20 组）：<ul><li><strong>RGB 图像</strong>：从 RGB 相机捕捉彩色图像。</li><li><strong>深度图像</strong>：从深度相机捕捉深度图（需与 RGB 图像对齐）。</li></ul></li><li><strong>多角度、多位置拍摄</strong>：确保标定板覆盖视场的不同区域，避免结果受视场中心点的偏差影响。</li></ul><hr><h3 id=3-标定过程><strong>3. 标定过程</strong></h3><h3 id=1rgb-相机内参标定><strong>（1）RGB 相机内参标定</strong></h3><ul><li>使用 RGB 图像中的标定板角点，标定 RGB 相机的内参：<ul><li>焦距 fx​,fy​</li><li>主点 cx​,cy​</li><li>畸变参数 k1​,k2​,…</li></ul></li><li>使用 OpenCV 的 <code>cv2.calibrateCamera</code> 函数实现。</li></ul><h3 id=2深度相机内参标定><strong>（2）深度相机内参标定</strong></h3><ul><li>同样基于标定板，标定深度相机的内参。</li></ul><h3 id=3外参标定><strong>（3）外参标定</strong></h3><ul><li><p>通过标定板角点在 RGB 图像和深度图像中的位置关系，计算两者的外参（旋转矩阵 R 和平移向量 T）。</p><p>RR</p><p>TT</p></li><li><p>常用方法：</p><ul><li><strong>点云匹配法</strong>：<ul><li>将深度图转换为点云。</li><li>将 RGB 图像中的标定板角点对应到点云中，利用 ICP（Iterative Closest Point）算法估算外参。</li></ul></li><li><strong>直接标定法</strong>：<ul><li>使用 <code>cv2.stereoCalibrate</code>，将标定板角点作为对应点对输入，直接计算外参。</li></ul></li></ul></li></ul><h3 id=4验证标定结果><strong>（4）验证标定结果</strong></h3><ul><li>检查标定结果的准确性：<ul><li>使用外参将深度图像点投影到 RGB 图像，检查对齐效果。</li><li>若标定结果偏差大，可增加数据集或优化标定过程。</li></ul></li></ul><h2 id=接收器-or-发射器>接收器 or 发射器</h2><p><strong>外参标定主要针对 RGB 相机与深度接收器（深度相机模块）之间的几何关系，与发射器无直接关系。</strong></p><h3 id=外参标定与接收器的关系><strong>外参标定与接收器的关系</strong></h3><ul><li><strong>外参标定目标</strong>：<ul><li>标定的是**RGB 相机与深度接收器（即深度相机的感应模块）**之间的相对位置和方向。</li><li>发射器只是深度接收器的辅助组件，其位置通常固定，且不会影响 RGB 与深度模块的几何关系，因此不需要单独标定发射器。</li></ul></li><li><strong>标定的原理</strong>：<ul><li>使用深度接收器捕获深度图，结合 RGB 相机捕获的彩色图像，通过标定板提取对应点对，计算两者的旋转矩阵 R 和平移向量 T。</li></ul></li></ul><h3 id=为什么发射器不参与外参标定><strong>为什么发射器不参与外参标定？</strong></h3><ol><li><strong>发射器只负责照明或投影</strong>：<ul><li>发射器的作用是辅助接收器生成深度图（例如通过投影图案或测量光传播时间）。</li><li>它本身并不直接生成深度数据。</li></ul></li><li><strong>与 RGB 图像无直接对应关系</strong>：<ul><li>RGB 图像与深度图的对齐是通过接收器获取的数据完成的，而非发射器。</li></ul></li><li><strong>相对位置固定</strong>：<ul><li>在大多数 RGB-D 相机中，发射器与接收器的相对位置是出厂前固定的，通常无需额外标定。</li></ul></li></ol><h1 id=准确性>准确性</h1><h1 id=常见问题>常见问题</h1><h2 id=缺失值nan>缺失值nan</h2><p>深度相机（如 Kinect、Intel RealSense 或 Azure Kinect 等）在工作过程中，由于硬件限制、采集环境或处理算法的原因，可能会在生成的深度图或点云数据中产生 <strong>NaN</strong> 值。这些 NaN 值通常表示传感器在某些像素位置无法测量到有效的深度值。</p><h3 id=1-透明或高反射物体><strong>1. 透明或高反射物体</strong></h3><h3 id=原因><strong>原因：</strong></h3><ul><li>深度相机的原理通常是红外结构光或 ToF（飞行时间），对于透明物体（如玻璃、水）或高反射物体（如镜子、金属），红外光可能会：<ul><li>穿透透明物体而未返回有效信号。</li><li>被高反射表面散射，导致接收不到反射信号。</li></ul></li></ul><h3 id=表现><strong>表现：</strong></h3><p>这些区域的深度值无法被检测到，结果为 NaN 或无效值。</p><h3 id=2-测量范围限制><strong>2. 测量范围限制</strong></h3><h3 id=原因-1><strong>原因：</strong></h3><ul><li>深度相机通常有一个有效的工作距离范围（例如 0.5 米到 5 米）。如果物体距离传感器太近或太远，设备可能无法正确测量深度值。</li></ul><h3 id=表现-1><strong>表现：</strong></h3><ul><li>超出范围的像素点会被记录为 NaN。</li><li>近距离（如遮挡物贴近镜头）或远距离（如视野范围外）会导致无效数据。</li></ul><h3 id=3-采集环境中的干扰><strong>3. 采集环境中的干扰</strong></h3><h3 id=原因-2><strong>原因：</strong></h3><ul><li>环境中的强光（例如阳光直射）会<strong>干扰深度相机的红外光</strong>，降低传感器的信号质量。</li><li>雾霾、烟尘或其他粒子散射红外光，也会影响深度测量。</li></ul><h3 id=表现-2><strong>表现：</strong></h3><ul><li>受干扰区域的深度值可能丢失或记录为 NaN。</li></ul><h3 id=4-视角问题和遮挡><strong>4. 视角问题和遮挡</strong></h3><h3 id=原因-3><strong>原因：</strong></h3><ul><li><strong>视角问题</strong>：深度相机的测量方向与物体表面角度不一致，可能导致反射信号过弱或完全丢失。</li><li><strong>遮挡问题</strong>：一个物体遮挡了另一个物体，导致被遮挡区域无法接收到红外信号。</li></ul><h3 id=表现-3><strong>表现：</strong></h3><ul><li>被遮挡或大角度表面的区域会出现 NaN。</li></ul><h3 id=5-数据插值或重建失败><strong>5. 数据插值或重建失败</strong></h3><h3 id=原因-4><strong>原因：</strong></h3><ul><li>在生成点云或深度图时，某些深度值可能需要插值处理。如果周围没有足够的有效点，插值可能失败，导致 NaN。</li></ul><h3 id=表现-4><strong>表现：</strong></h3><ul><li>插值失败的像素位置为 NaN。</li></ul><h3 id=6-软件或硬件问题><strong>6. 软件或硬件问题</strong></h3><h3 id=原因-5><strong>原因：</strong></h3><ul><li><strong>软件问题</strong>：传感器驱动、SDK 或中间件（如 ROS）的数据处理过程中出现异常。</li><li><strong>硬件问题</strong>：传感器的光学元件或接收模块损坏，导致信号采集失败。</li></ul><h3 id=表现-5><strong>表现：</strong></h3><ul><li>整体深度数据中可能出现大范围 NaN 或随机分布的 NaN。</li></ul><h3 id=7-校准误差><strong>7. 校准误差</strong></h3><h3 id=原因-6><strong>原因：</strong></h3><ul><li>深度相机在出厂或使用时需要校准。如果校准不准确，会导致测量误差，在某些情况下直接导致 NaN。</li></ul><h3 id=表现-6><strong>表现：</strong></h3><ul><li>某些视野区域深度数据异常，甚至无法测量。</li></ul></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2025-04-29</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/ data-title=RGB-D相机 data-hashtags=RGBD,传感器,硬件,3d><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/ data-hashtag=RGBD><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/ data-title=RGB-D相机><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/ data-title=RGB-D相机><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://fjyu95.github.io/posts/rgb-d-cam-170e4020f06080198bd5cb4e98e89580/ data-title=RGB-D相机><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/rgbd/>RGBD</a>,&nbsp;<a href=/tags/%E4%BC%A0%E6%84%9F%E5%99%A8/>传感器</a>,&nbsp;<a href=/tags/%E7%A1%AC%E4%BB%B6/>硬件</a>,&nbsp;<a href=/tags/3d/>3d</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/dust3r-series-15ee4020f0608006803bfe528b97cab2/ class=prev rel=prev title=DUSt3R系列学习><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>DUSt3R系列学习</a>
<a href=/posts/ros-17ae4020f0608037ab9ce65eddd62e49/ class=next rel=next title=ROS>ROS<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.145.0">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.3.0"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2020 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://fjyu95.github.io/ target=_blank>fjyu95</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>