<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>视觉slam - FangjieYu‘s site</title><meta name=Description content="This is my cool site"><meta property="og:url" content="https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/">
<meta property="og:site_name" content="FangjieYu‘s site"><meta property="og:title" content="视觉slam"><meta property="og:description" content="视觉slam基础知识总结"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-10-22T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-16T00:00:00+00:00"><meta property="article:tag" content="3d"><meta property="article:tag" content="Slam"><meta name=twitter:card content="summary"><meta name=twitter:title content="视觉slam"><meta name=twitter:description content="视觉slam基础知识总结"><meta name=application-name content="My cool site"><meta name=apple-mobile-web-app-title content="My cool site"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/><link rel=prev href=https://fjyu95.github.io/posts/algorithm_knowledge_base/8_%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/><link rel=next href=https://fjyu95.github.io/posts/algorithm_knowledge_base/6_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"视觉slam","inLanguage":"en-us","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/fjyu95.github.io\/posts\/algorithm_knowledge_base\/7_vslam\/"},"genre":"posts","keywords":"3d, slam","wordcount":6392,"url":"https:\/\/fjyu95.github.io\/posts\/algorithm_knowledge_base\/7_vslam\/","datePublished":"2024-10-22T00:00:00+00:00","dateModified":"2025-04-16T00:00:00+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"fjyu95"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title="FangjieYu‘s site">fjyu95</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>posts </a><a class=menu-item href=/tags/>tags </a><a class=menu-item href=/categories/>category </a><a class=menu-item href=/about/>about </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="FangjieYu‘s site">fjyu95</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>posts</a><a class=menu-item href=/tags/ title>tags</a><a class=menu-item href=/categories/ title>category</a><a class=menu-item href=/about/ title>about</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">视觉slam</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://fjyu95.github.io/ title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>fjyu95</a></span>&nbsp;<span class=post-category>included in <a href=/categories/%E7%AE%97%E6%B3%95%E7%9F%A5%E8%AF%86%E5%BA%93/><i class="far fa-folder fa-fw" aria-hidden=true></i>算法知识库</a>&nbsp;<a href=/categories/slam/><i class="far fa-folder fa-fw" aria-hidden=true></i>Slam</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2024-10-22>2024-10-22</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;6392 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;13 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#视觉slam>视觉slam</a><ul><li><a href=#视觉slam框架>视觉slam框架</a></li><li><a href=#数学基础>数学基础</a><ul><li><a href=#齐次坐标>齐次坐标</a></li><li><a href=#内外积>内外积</a></li></ul></li><li><a href=#svd分解>SVD分解</a><ul><li><a href=#1-svd的数学形式>1. <strong>SVD的数学形式</strong></a></li><li><a href=#2-奇异值>2. <strong>奇异值</strong></a></li><li><a href=#3-几何解释>3. <strong>几何解释</strong></a></li></ul></li><li><a href=#非线性优化>非线性优化</a></li><li><a href=#几种投影变换>几种投影变换</a><ul><li><a href=#三维仿射变换>三维仿射变换</a></li></ul></li><li><a href=#三维刚体运动表示>三维刚体运动表示</a><ul><li><a href=#1旋转矩阵--不够紧凑冗余优化困难带有约束>1、旋转矩阵 <strong>不够紧凑、冗余、优化困难（带有约束）</strong></a></li><li><a href=#2旋转向量-轴-角表示法>2、旋转向量 轴-角表示法</a></li><li><a href=#3欧拉角-直观>3、欧拉角 <strong>直观</strong></a></li><li><a href=#4四元数>4、四元数</a></li></ul></li><li><a href=#相机模型>相机模型</a><ul><li><a href=#针孔相机模型>针孔相机模型</a></li><li><a href=#双目相机>双目相机</a></li><li><a href=#rgb-d相机-结构光tof>RGB-D相机 结构光、ToF</a></li></ul></li><li><a href=#相机畸变>相机畸变</a><ul><li><a href=#径向畸变>径向畸变</a></li><li><a href=#切向畸变>切向畸变</a></li><li><a href=#畸变校正>畸变校正</a></li></ul></li><li><a href=#相机标定>相机标定</a><ul><li><a href=#相机标定的目的>相机标定的目的</a></li></ul></li><li><a href=#视觉里程计>视觉里程计</a><ul><li><a href=#视觉里程计的基本原理>视觉里程计的基本原理</a></li><li><a href=#视觉里程计的分类>视觉里程计的分类</a></li><li><a href=#常用的视觉里程计算法>常用的视觉里程计算法</a></li></ul></li><li><a href=#2d-2d-对极几何>2d-2d 对极几何</a><ul><li><a href=#基础矩阵f>基础矩阵F</a></li><li><a href=#本质矩阵e>本质矩阵E</a></li><li><a href=#单应矩阵h>单应矩阵H</a></li><li><a href=#自由度>自由度</a></li></ul></li><li><a href=#3d-2d-pnp>3d-2d PnP</a><ul><li><a href=#pnp问题的定义>PnP问题的定义</a></li><li><a href=#pnp问题的求解步骤>PnP问题的求解步骤</a></li><li><a href=#dltdirect-linear-transformation><strong>DLT（Direct Linear Transformation）</strong></a></li><li><a href=#p3p>P3P</a></li><li><a href=#bundle-adjustment>Bundle Adjustment</a></li><li><a href=#光束法平差的基本原理>光束法平差的基本原理</a></li></ul></li><li><a href=#3d-3d-icp>3d-3d ICP</a></li><li><a href=#三角测量空间前方交会-已知观察未知>三角测量（空间前方交会 已知观察未知）</a></li><li><a href=#orb-slam2>orb-slam2</a></li></ul></li></ul></nav></div></div><div class=content id=content><h1 id=视觉slam>视觉slam</h1><p><a href=https://wykxwyc.github.io/2019/03/21/Small-Talk/ target=_blank rel="noopener noreffer">一个不起眼的烂笔头</a></p><h2 id=视觉slam框架>视觉slam框架</h2><img src=image.png width=75%><p>整个视觉 SLAM 流程包括以下步骤。</p><ol><li>传感器信息读取。在视觉 SLAM 中主要为相机图像信息的读取和预处理。如果是在机器人中，还可能有码盘、惯性传感器等信息的读取和同步。</li><li>视觉里程计（Visual Odometry，VO）。视觉里程计的任务是<strong>估算相邻图像间相机的运动，以及局部地图的样子</strong>。VO 又称为前端（Front End）。</li><li>后端优化（Optimization）。后端接受不同时刻视觉里程计测量的相机位姿，以及<strong>回环检测</strong>的信息，对它们进行<strong>优化，得到全局一致的轨迹和地图</strong>。由于接在 VO 之后，又称为后端（Back End）。</li><li>回环检测（Loop Closing）。回环检测判断机器人是否到达过先前的位置。如果检测到回环，它会把信息提供给后端进行处理。</li><li>建图（Mapping）。它根据估计的轨迹，建立与任务要求对应的地图。</li></ol><h2 id=数学基础>数学基础</h2><p>向量一般默认指列向量</p><h3 id=齐次坐标>齐次坐标</h3><p><a href=https://blog.csdn.net/zhuiqiuzhuoyue583/article/details/95228010 target=_blank rel="noopener noreffer">为什么要引入齐次坐标，齐次坐标的意义（一)</a></p><p><a href=https://blog.csdn.net/zhuiqiuzhuoyue583/article/details/95230246 target=_blank rel="noopener noreffer">为什么要引入齐次坐标，齐次坐标的意义（二)</a></p><p><strong>齐次坐标可以表示无穷远处的点。</strong></p><p><strong>齐次坐标把各种变换都统一了起来，即 把缩放，旋转，平移等变换都统一起来，都表示成一连串的矩阵相乘的形式。保证了形式上的线性一致性。</strong></p><p>齐次坐标就是将一个原本是n维的向量用一个n+1维向量来表示，<strong>合并矩阵运算中的乘法和加法，简化运算操作。</strong></p><h3 id=内外积>内外积</h3><p><a href=https://www.zhihu.com/question/21080171 target=_blank rel="noopener noreffer">点乘和叉乘</a></p><p><strong>内积</strong></p><p>数量积 点乘 一个数</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%201.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%201.png, /posts/algorithm_knowledge_base/7_vslam/image%201.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%201.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%201.png title=image.png width=361 height=63></p><p><strong>外积</strong></p><p>向量积 叉乘 一个向量</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%202.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%202.png, /posts/algorithm_knowledge_base/7_vslam/image%202.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%202.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%202.png title=image.png width=662 height=114></p><p>方向垂直于两个向量，大小为 |a| |b| sin ⟨a, b⟩，是两个向量张成的四边形的有向面积</p><p>把外积 a × b 写成了矩阵与向量的乘法 a∧ b，把它变成了线性运算</p><p>∧ 记成一个反对称符号，<strong>任意向量都对应着唯一的一个反对称矩阵</strong></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%203.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%203.png, /posts/algorithm_knowledge_base/7_vslam/image%203.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%203.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%203.png title=image.png width=249 height=127></p><h2 id=svd分解>SVD分解</h2><p><a href=https://zhuanlan.zhihu.com/p/79669616 target=_blank rel="noopener noreffer">https://zhuanlan.zhihu.com/p/79669616</a></p><p><a href=https://zhaoxuhui.top/blog/2018/03/17/SVD&amp;SLAM.html target=_blank rel="noopener noreffer">https://zhaoxuhui.top/blog/2018/03/17/SVD&SLAM.html</a></p><p><a href=https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html target=_blank rel="noopener noreffer">https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html</a></p><h3 id=1-svd的数学形式>1. <strong>SVD的数学形式</strong></h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%204.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%204.png, /posts/algorithm_knowledge_base/7_vslam/image%204.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%204.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%204.png title=image.png width=595 height=256></p><h3 id=2-奇异值>2. <strong>奇异值</strong></h3><ul><li>奇异值是矩阵 A 的非负平方根，表示了矩阵在不同方向上的“重要性”或“能量”。较大的奇异值对应于矩阵中更重要的特征，而较小的奇异值则表示较不重要的特征。</li><li>通过奇异值的大小，可以判断矩阵的秩、条件数以及数据的可分性。</li></ul><h3 id=3-几何解释>3. <strong>几何解释</strong></h3><ul><li><p>SVD 的几何解释是将数据空间的线性变换可视化。矩阵 A 可以被视为将输入空间中的点映射到输出空间。通过 SVD，可以将这个映射过程分解为三个步骤：</p><p>AA</p><ol><li><strong>旋转</strong>（通过 VT）将输入空间中的点旋转到新的坐标系。</li><li><strong>缩放</strong>（通过 Σ）在新的坐标系中按奇异值的大小缩放。</li><li><strong>再次旋转</strong>（通过 U）将缩放后的点旋转到输出空间。</li></ol></li></ul><p><strong>应用</strong></p><p>数据降维 PCA</p><p>矩阵近似</p><p>图像压缩</p><p>numpy scipy已实现</p><h2 id=非线性优化>非线性优化</h2><p>待续&mldr;</p><h2 id=几种投影变换>几种投影变换</h2><p><strong>仿射变换=线性变换+平移</strong></p><p><strong>平移、旋转、放缩、剪切、反射</strong></p><p><a href=https://blog.csdn.net/sgfmby1994/article/details/62426331 target=_blank rel="noopener noreffer">https://blog.csdn.net/sgfmby1994/article/details/62426331</a></p><p><a href=https://www.cnblogs.com/shine-lee/p/10950963.html target=_blank rel="noopener noreffer">https://www.cnblogs.com/shine-lee/p/10950963.html</a></p><p>projective/perspective：三维到二维的变换</p><p>Homography：两个平面间的映射，描述<strong>同一平面在不同视角下的变换</strong></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%205.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%205.png, /posts/algorithm_knowledge_base/7_vslam/image%205.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%205.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%205.png title=image.png width=751 height=266></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%206.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%206.png, /posts/algorithm_knowledge_base/7_vslam/image%206.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%206.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%206.png title=image.png width=1173 height=642></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%207.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%207.png, /posts/algorithm_knowledge_base/7_vslam/image%207.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%207.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%207.png title=image.png width=975 height=528></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%208.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%208.png, /posts/algorithm_knowledge_base/7_vslam/image%208.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%208.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%208.png title=image.png width=481 height=314></p><p><strong>二维仿射变换</strong>是一种线性变换，保持直线性和平行性。可以进行平移、旋转、缩放、剪切等操作，常见于图像处理、计算机图形学等领域。</p><p>二维仿射变换可以用一个 3×3 的矩阵来表示：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=%209.png data-srcset="%209.png, %209.png 1.5x, %209.png 2x" data-sizes=auto alt=%209.png title=image.png></p><p>其中，(x,y)(x, y)(x,y) 是原始点的坐标，(x′,y′)(x&rsquo;, y&rsquo;)(x′,y′) 是变换后的坐标，a,b,c,da, b, c, da,b,c,d 定义线性变换（旋转、缩放、剪切等），而 tx,tytx, tytx,ty 代表平移。</p><h3 id=三维仿射变换>三维仿射变换</h3><p><strong>三维仿射变换</strong>扩展了二维仿射变换，允许在三维空间中进行类似的操作，如平移、旋转、缩放和剪切等。它通常用 4×4 的矩阵来表示：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2010.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2010.png, /posts/algorithm_knowledge_base/7_vslam/image%2010.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2010.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2010.png title=image.png width=283 height=109></p><p>其中，(x,y,z)(x, y, z)(x,y,z) 是原始点的坐标，(x′,y′,z′)(x&rsquo;, y&rsquo;, z&rsquo;)(x′,y′,z′) 是变换后的坐标，矩阵 aija_{ij}aij 代表线性变换，而 tx,ty,tztx, ty, tztx,ty,tz 代表平移。</p><h2 id=三维刚体运动表示>三维刚体运动表示</h2><h3 id=1旋转矩阵--不够紧凑冗余优化困难带有约束>1、旋转矩阵 <strong>不够紧凑、冗余、优化困难（带有约束）</strong></h3><p>4×4 的矩阵，将平移和旋转结合在一起，写成齐次坐标形式</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2011.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2011.png, /posts/algorithm_knowledge_base/7_vslam/image%2011.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2011.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2011.png title=image.png width=119 height=65></p><p>R是9个量表示3个自由度</p><p>有三个互相垂直的坐标轴（x, y, z）。旋转矩阵的 <strong>每一列</strong> 表示<strong>旋转后的坐标轴在原坐标系中的方向。</strong></p><p>例如世界坐标系到相机坐标系的旋转变换中，旋转矩阵的列向量表示的是相机坐标系的x、y、z轴在世界坐标系中的方向。</p><p><strong>列向量表示旋转后的基向量</strong>：</p><ul><li>旋转矩阵的每一列表示旋转后坐标轴上的基向量（单位向量）在原坐标系中的表示。</li><li>例如，第一列表示旋转后x轴上的基向量在原坐标系中的坐标，第二列和第三列分别表示旋转后y轴和z轴上的基向量。</li></ul><p><strong>旋转角度和轴</strong>：</p><ul><li>旋转矩阵可以唯一地确定一个旋转的角度和旋转轴。</li><li>通过旋转矩阵，可以计算出旋转的角度（通常使用弧度表示）和旋转轴的方向。</li></ul><p><strong>无奇异性</strong></p><h3 id=2旋转向量-轴-角表示法>2、旋转向量 轴-角表示法</h3><p>方向与旋转轴一致，长度等于旋转角**（3维向量）**</p><p>旋转向量通常表示为 r=θu，其中：</p><ul><li>r是旋转向量。</li><li>θ是旋转角度（弧度）。例 θ=π/2</li><li>u是单位向量，表示旋转轴。例 u=(0.707,0,0.707)</li></ul><h3 id=3欧拉角-直观>3、欧拉角 <strong>直观</strong></h3><p>Yaw（偏航角）、Pitch（俯仰角）和 Roll（翻滚角）</p><p>万向锁问题（丢失自由度）rpy</p><h3 id=4四元数>4、四元数</h3><p>既是紧凑的，也没有奇异性</p><p>没有欧拉角的万向节锁问题，适合进行连续旋转的插值计算</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2012.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2012.png, /posts/algorithm_knowledge_base/7_vslam/image%2012.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2012.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2012.png title=image.png width=551 height=91></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2013.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2013.png, /posts/algorithm_knowledge_base/7_vslam/image%2013.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2013.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2013.png title=image.png width=659 height=392></p><p>表示方法 维度 直观性 计算效率 是否有奇异性<br>旋转矩阵 3×3 一般 慢（9 个数） 无<br>欧拉角 3 直观 快 有（万向锁问题）<br>四元数 4 不直观 快 无<br>旋转向量 3 直观 快 无</p><h2 id=相机模型>相机模型</h2><p>物理空间Z=1的<strong>归一化平面与像素坐标系只差一个内参矩阵K</strong>，Puv = KPc</p><h3 id=针孔相机模型>针孔相机模型</h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2014.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2014.png, /posts/algorithm_knowledge_base/7_vslam/image%2014.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2014.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2014.png title=image.png width=600 height=292></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2015.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2015.png, /posts/algorithm_knowledge_base/7_vslam/image%2015.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2015.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2015.png title=image.png width=600 height=266></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2016.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2016.png, /posts/algorithm_knowledge_base/7_vslam/image%2016.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2016.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2016.png title=image.png width=464 height=144></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2017.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2017.png, /posts/algorithm_knowledge_base/7_vslam/image%2017.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2017.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2017.png title=image.png width=459 height=140></p><p>比例因子α, β 的单位为<strong>像素/米，把物理距离转换为像素距离</strong></p><p>相机内参fx , fy代表<strong>焦距f长度对应的像素距离</strong></p><p>主点坐标cx,cy代表相机光心在图像上的投影点位置，一般是图像的像素中心</p><p>单目相机的成像过程（针孔相机模型）：</p><ol><li>首先，世界坐标系下有一个固定的点 P ，世界坐标为 Pw 。</li><li>由于相机在运动，它的运动由 R, t 或变换矩阵 T ∈ SE(3) 描述。P 的相机坐标为 P̃c =RPw + t。</li><li>这时的 P̃c 的分量为 X, Y, Z，把它们<strong>投影到归一化平面 Z = 1 上</strong>，得到 P 的归一化坐标：Pc = [X/Z, Y /Z, 1]T。</li><li>有畸变时，根据畸变参数计算 Pc 发生畸变后的坐标。</li><li>最后，P 的归一化坐标经过内参后，对应到它的像素坐标：Puv = KPc 。<br>综上所述，我们一共谈到了四种坐标：世界坐标、相机坐标、归一化坐标和像素坐标。</li></ol><h3 id=双目相机>双目相机</h3><p>利用基线长度b、视差d来估算深度</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2018.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2018.png, /posts/algorithm_knowledge_base/7_vslam/image%2018.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2018.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2018.png title=image.png width=817 height=376></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2019.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2019.png, /posts/algorithm_knowledge_base/7_vslam/image%2019.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2019.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2019.png title=image.png width=220 height=119></p><p><strong>视差越小，深度越远</strong></p><p><strong>基线越长，测量越远</strong></p><h3 id=rgb-d相机-结构光tof>RGB-D相机 结构光、ToF</h3><p>深度图转点云 相似三角形原理</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2020.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2020.png, /posts/algorithm_knowledge_base/7_vslam/image%2020.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2020.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2020.png title=image.png width=1587 height=1122></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2021.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2021.png, /posts/algorithm_knowledge_base/7_vslam/image%2021.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2021.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2021.png title=image.png width=189 height=112></p><p>假设内参已知，知道Z的信息后，就可推算出像素坐标u,v对应的X,Y空间坐标</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2022.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2022.png, /posts/algorithm_knowledge_base/7_vslam/image%2022.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2022.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2022.png title=image.png width=219 height=81></p><h2 id=相机畸变>相机畸变</h2><h3 id=径向畸变>径向畸变</h3><p>由透镜形状引起的畸变</p><p>桶形畸变和枕形畸变</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2023.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2023.png, /posts/algorithm_knowledge_base/7_vslam/image%2023.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2023.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2023.png title=image.png width=627 height=245></p><h3 id=切向畸变>切向畸变</h3><p>相机的组装过程中透镜和成像面不严格平行</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2024.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2024.png, /posts/algorithm_knowledge_base/7_vslam/image%2024.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2024.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2024.png title=image.png width=615 height=385></p><h3 id=畸变校正>畸变校正</h3><p>对于相机坐标系中的一点 P ，我们能够通过 5 个畸变系数找到这个点在像素平面上的正确位置：</p><ol><li>将三维空间点投影到归一化图像平面。设它的归一化坐标为 [x, y]T 。</li><li>对<strong>归一化平面上</strong>的点计算径向畸变和切向畸变。Z值（深度）为1的假设平面</li></ol><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2025.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2025.png, /posts/algorithm_knowledge_base/7_vslam/image%2025.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2025.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2025.png title=image.png width=533 height=80></p><p>将畸变后的点通过内参数矩阵投影到像素平面，得到该点在图像上的正确位置。</p><h2 id=相机标定>相机标定</h2><h3 id=相机标定的目的>相机标定的目的</h3><ol><li><strong>校正畸变</strong>：大多数相机镜头都会产生一定的畸变，常见的有径向畸变和切向畸变。标定可以获取相机的畸变系数，进而校正图像，使其符合真实场景。</li><li><strong>获取内参矩阵</strong>：相机的内参描述了相机的焦距、主点位置等信息。内参矩阵在将三维空间的点投影到二维图像上时非常重要。</li><li><strong>获取外参矩阵</strong>：外参描述了相机在三维空间中的位置和姿态，通常以旋转矩阵和位移向量表示。外参矩阵可以用于计算相机与世界坐标系的关系。</li></ol><p><a href=https://zhuanlan.zhihu.com/p/94244568 target=_blank rel="noopener noreffer">zhuanlan.zhihu.com</a></p><p>张正友标定法标定相机的内外参数的思路如下：</p><p>将世界坐标系固定于棋盘格上，则棋盘格上任一点的物理坐标W=0，任一角点的U、V坐标也已知，<strong>最少4个角点就可以求解Homography矩阵</strong>。</p><p>1）、求解内参矩阵与外参矩阵的积，即H；</p><p>2）、求解内参矩阵K；</p><p>3）、求解外参矩阵T，KT=H；</p><p>4）、求解畸变参数。</p><h2 id=视觉里程计>视觉里程计</h2><p>特征点法、光流法（灰度不变假设）</p><p><a href=https://blog.csdn.net/qq_41839222/article/details/86483071 target=_blank rel="noopener noreffer">https://blog.csdn.net/qq_41839222/article/details/86483071</a></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2026.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2026.png, /posts/algorithm_knowledge_base/7_vslam/image%2026.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2026.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2026.png title=image.png width=812 height=152></p><p>视觉里程计（Visual Odometry，VO）是一种基于图像的技术，通过分<strong>析连续图像帧来估计相机（或移动设备）的运动轨迹</strong>。视觉里程计广泛应用于机器人、自动驾驶、增强现实（AR）和虚拟现实（VR）等领域，帮助设备在没有GPS或其他定位系统的环境中实现自我定位和导航。</p><h3 id=视觉里程计的基本原理>视觉里程计的基本原理</h3><p>视觉里程计利用相机捕获的连续图像帧中的视觉信息，通过特征提取和匹配来计算相机在空间中的位姿变化。主要的流程通常包括以下几个步骤：</p><ol><li><strong>特征提取</strong>：在图像中检测关键特征点，常用的特征检测算法有SIFT、SURF、ORB等。这些特征点可以用来跟踪相机运动。</li><li><strong>特征匹配</strong>：在相邻图像帧中，匹配提取的特征点，得到每个特征点在不同帧中的对应关系。</li><li><strong>估计运动（姿态估计）</strong>：通过匹配的特征点，使用PnP、ICP（Iterative Closest Point）或双目三角测量等方法<strong>计算相机的姿态变化，即位移和旋转（外参）</strong>。</li><li><strong>优化和滤波</strong>：使用优化算法（如Bundle Adjustment）来最小化重投影误差，提高运动估计的精度。对于长时间运行的系统，还可以加入滤波算法（如卡尔曼滤波、粒子滤波）来提高系统的鲁棒性。</li></ol><h3 id=视觉里程计的分类>视觉里程计的分类</h3><p>视觉里程计根据使用的图像传感器类型和特征提取方式可分为以下几类：</p><ol><li><strong>单目视觉里程计</strong><ul><li>使用单个相机，通常依赖特征点的运动来估计相机的位姿变化。</li><li>优点：硬件要求低，计算相对简单。</li><li>缺点：由于缺少深度信息，精度有限，依赖于图像特征点的质量。</li></ul></li><li><strong>双目视觉里程计</strong><ul><li>使用双目相机，利用双目视差来获取三维深度信息。</li><li>优点：可以直接获取深度信息，更精确地估计位姿变化。</li><li>缺点：硬件要求高于单目视觉。</li></ul></li><li><strong>RGB-D视觉里程计</strong><ul><li>使用RGB-D相机（如Kinect）获取带有深度信息的图像。</li><li>优点：直接获取深度信息，适用于室内环境。</li><li>缺点：受光线影响大，通常只适用于近距离场景。</li></ul></li><li><strong>特征点法与直接法</strong><ul><li>特征点法：通过检测和跟踪图像中的特征点，计算相机的运动。常用算法有ORB-SLAM、LDSO等。</li><li>直接法：直接利用图像灰度信息进行配准，如DSO（Direct Sparse Odometry）。<strong>在光线稳定、纹理丰富的情况下，直接法效率更高</strong>。</li></ul></li></ol><h3 id=常用的视觉里程计算法>常用的视觉里程计算法</h3><ol><li><strong>ORB-SLAM</strong>：<ul><li>基于特征点的SLAM（Simultaneous Localization and Mapping）方法，采用ORB特征，适合于多种类型相机。ORB-SLAM包含回环检测和重定位等模块，非常适合长期运行。</li></ul></li><li><strong>LSD-SLAM</strong>：<ul><li>基于稀疏直接法的SLAM方法，使用图像灰度值进行位姿估计，适合在低纹理场景下运行。主要用于单目相机。</li></ul></li><li><strong>DSO（Direct Sparse Odometry）</strong>：<ul><li>直接法的视觉里程计，通过稀疏图像配准直接估计相机位姿，在非特征丰富的场景中表现良好，且计算速度较快。</li></ul></li><li><strong>VINS-Mono / VINS-Fusion</strong>：<ul><li>基于因子图优化的视觉里程计算法，融合IMU（惯性测量单元）数据，提升了单目相机在三维空间中的定位精度，特别适用于动态环境中。</li></ul></li></ol><h2 id=2d-2d-对极几何>2d-2d 对极几何</h2><p><a href=https://www.cnblogs.com/narjaja/p/10768179.html target=_blank rel="noopener noreffer">https://www.cnblogs.com/narjaja/p/10768179.html</a></p><p><strong>通过二维图像点的对应关系，恢复出在两帧之间摄像机的运动</strong></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2027.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2027.png, /posts/algorithm_knowledge_base/7_vslam/image%2027.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2027.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2027.png title=image.png width=1181 height=344></p><p>对极约束简洁地给出了两个匹配点的空间位置关系。相机位姿估计问题变为以下两步：</p><ol><li>根据配对点的像素位置求出 E 或者 F （都可以8点法求解）。</li><li>根据 E 或者 F 求出 R, t。<br>由于 E 和 F 只相差了相机内参，而内参在 SLAM 中通常是已知的 ，所以实践当中往往使用形式更简单的 E。</li></ol><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2028.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2028.png, /posts/algorithm_knowledge_base/7_vslam/image%2028.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2028.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2028.png title=image.png width=192 height=43></p><pre><code>                                      x是归一化平面上的坐标，p是像素坐标。
</code></pre><h3 id=基础矩阵f>基础矩阵F</h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2029.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2029.png, /posts/algorithm_knowledge_base/7_vslam/image%2029.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2029.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2029.png title=image.png width=163 height=78></p><p>基础矩阵是一个 3×3 的矩阵，定义了在两个视图中对应点之间的约束关系。给定两个视图中的一个对应点对 (x,x′)，它们满足以下关系：</p><pre><code>                                                   x′TFx=0
</code></pre><p>其中：</p><ul><li><p>x和 x′ 分别是图像1和图像2中的对应点的齐次坐标。</p></li><li><p>F是基础矩阵，描述两个图像之间的对应关系，具有 7 个自由度</p><pre><code>                        （*detF*=0的约束、尺度等价性各减去一个自由度）。
</code></pre></li></ul><p>基础矩阵的作用是将图像1中的点通过约束关系映射到图像2中相应的极线，建立点和极线的关系。由于基础矩阵不依赖于相机内参，因此它可以应用于任意两个视图，<strong>适用于未标定的摄像机</strong>。<strong>8点法求解</strong></p><h3 id=本质矩阵e>本质矩阵E</h3><p>不包含内参</p><p><strong>本质矩阵 E = t∧ R</strong>。它是一个 3 × 3 的矩阵，内有 9 个未知数</p><p>平移向量 t 对应的反对称矩阵 <strong>t∧</strong> 与旋转矩阵 R 的乘积</p><p>5个自由度（平移和旋转各有 3 个自由度，尺度等价性减去1个自由度）</p><p><strong>8点法求解</strong>（最少5点）</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2030.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2030.png, /posts/algorithm_knowledge_base/7_vslam/image%2030.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2030.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2030.png title=image.png width=820 height=354></p><p>系数矩阵是根据对 e 的多项式进行拆分得到的</p><p>再对E进行SVD分解恢复R,t</p><h3 id=单应矩阵h>单应矩阵H</h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2031.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2031.png, /posts/algorithm_knowledge_base/7_vslam/image%2031.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2031.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2031.png title=image.png width=299 height=202></p><p>p2 ≃ Hp1 . nT是平面P的法向量，d是平面常数项参数</p><p>纯旋转或特征点在同一平面</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2032.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2032.png, /posts/algorithm_knowledge_base/7_vslam/image%2032.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2032.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2032.png title=image.png width=271 height=119></p><p>自由度为 8 的单应矩阵可以通过 <strong>4 对匹配特征点</strong>算出 DLT求解</p><p>可分解出R、t 数值法或解析法</p><h3 id=自由度>自由度</h3><ul><li>单应矩阵有 8 个自由度。尽管它包含 9 个元素 hij，但由于其定义是 up-to-scale 的（即在同一个变换下，矩阵的所有元素乘以一个非零常数仍然描述相同的单应性变换），所以只需要 8 个独立参数来确定这个矩阵。</li><li>为了固定尺度，<strong>一般将 h33 归一化为 1 或将矩阵整体除以某一个元素，以便矩阵变换唯一确定</strong>。</li></ul><h2 id=3d-2d-pnp>3d-2d PnP</h2><p>Perspective-n-Point</p><p>通过一组已知的三维点及其在二维图像中的投影点来确定相机姿态（位姿，即旋转和平移）的算法。</p><p><a href=https://www.zywvvd.com/notes/study/camera-imaging/pnp/pnp/ target=_blank rel="noopener noreffer">https://www.zywvvd.com/notes/study/camera-imaging/pnp/pnp/</a></p><h3 id=pnp问题的定义>PnP问题的定义</h3><p>给定：</p><ol><li><strong>n个三维点的坐标</strong>：在物体坐标系中，这些点的三维坐标已知，表示为(Xi​,Yi​,Zi​)。</li><li><strong>n个二维图像点</strong>：这些三维点在图像平面上的投影位置已知，表示为(xi​,yi​)。</li><li><strong>相机内参矩阵</strong>：<strong>已知相机的内参矩阵K</strong>，包括焦距和主点位置等参数。内参未知时可尝试UPnP或同时估计内外参的方法，但这些方法通常比已知内参的PnP问题更复杂，并且可能对噪声和初始化更敏感。</li></ol><p><strong>目标是求解相机的外参</strong>，即相机相对于物体的旋转矩阵 R 和平移向量 t，将三维点投影到图像上。</p><h3 id=pnp问题的求解步骤>PnP问题的求解步骤</h3><ol><li><p><strong>模型建立</strong>：在相机坐标系中，根据相机内参矩阵和外参矩阵，得到3D点到2D点的投影关系公式。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2033.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2033.png, /posts/algorithm_knowledge_base/7_vslam/image%2033.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2033.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2033.png title=image.png width=212 height=116></p></li></ol><ul><li>其中 K为相机内参矩阵，[R∣t][R | t][R∣t] 为外参矩阵。</li><li><strong>方程求解</strong>：根据不同方法（如EPnP、RANSAC+PnP等）求解出R 和 t。</li><li><strong>优化与精确化</strong>：通常会进行非线性优化（如Levenberg-Marquardt），以最小化重投影误差，进一步精确外参矩阵。</li><li><strong>验证与应用</strong>：将解出的姿态应用到实际场景中，可以得到相机的位置和方向。</li></ul><h3 id=dltdirect-linear-transformation><strong>DLT（Direct Linear Transformation）</strong></h3><p>空间点P，齐次坐标为 P = (X, Y, Z, 1)T，投影到特征点 x1 =(u1 , v1 , 1)T （归一化平面，与图像点只差一个内参，因此可等效替代）</p><p>定义增广矩阵 [R|t] 为一个 3 × 4 的矩阵，包含了旋转与平移信息</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2034.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2034.png, /posts/algorithm_knowledge_base/7_vslam/image%2034.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2034.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2034.png title=image.png width=658 height=246></p><p>12个未知数，一对匹配点提供2个关于t的线性约束</p><ul><li>在<strong>点数多于6个的情况下</strong>，通过线性方法直接求解PnP问题。DLT方法虽然简单，但易受噪声影响，因此通常用于粗略估计。</li><li>优势：实现简单，但对噪声敏感。</li></ul><h3 id=p3p>P3P</h3><p><a href=https://www.cnblogs.com/mafuqiang/p/8302663.html target=_blank rel="noopener noreffer">https://www.cnblogs.com/mafuqiang/p/8302663.html</a></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2035.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2035.png, /posts/algorithm_knowledge_base/7_vslam/image%2035.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2035.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2035.png title=image.png width=394 height=317></p><p>将P3P问题<strong>转换为ICP问题求解</strong>，核心是求解3个2d点在当前相机坐标系下的3d坐标</p><p>需要求解二元二次方程，最少需要一个点，还需要<strong>额外的第4个点验证</strong></p><p>方程的建立是依据余弦定理</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2036.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2036.png, /posts/algorithm_knowledge_base/7_vslam/image%2036.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2036.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2036.png title=image.png width=381 height=117></p><h3 id=bundle-adjustment>Bundle Adjustment</h3><p>定义于李代数上的非线性最小二乘问题</p><p><strong>最小化重投影误差</strong></p><p>没有回环也可以做局部BA</p><h3 id=光束法平差的基本原理>光束法平差的基本原理</h3><ol><li><p><strong>已知条件</strong>：</p><ul><li>多个视角下的图像以及对应的特征点。</li><li>每个视角的相机内参（如焦距、主点位置、畸变系数）和外参（位置和朝向）。</li></ul></li><li><p><strong>目标</strong>：</p><ul><li><strong>优化相机的内外参数和三维点的位置</strong>，使得通过相机投影回到图像的三维点与实际检测到的二维特征点之间的重投影误差最小。</li></ul></li><li><p><strong>重投影误差</strong>：</p><ul><li>重投影误差是指将三维点通过相机模型投影到图像平面后，<strong>计算得到的二维点与实际检测到的二维特征点之间的差距</strong>。这个误差通常用平方和来表示：</li></ul><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2037.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2037.png, /posts/algorithm_knowledge_base/7_vslam/image%2037.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2037.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2037.png title=image.png width=290 height=53></p><p>其中，pij是第j个相机观察到的第i个三维点的实际图像位置，π是投影函数，Rj和tj是第j个相机的旋转和位移。</p></li></ol><h2 id=3d-3d-icp>3d-3d ICP</h2><p><a href=https://zhuanlan.zhihu.com/p/96908474 target=_blank rel="noopener noreffer">zhuanlan.zhihu.com</a></p><p><strong>两种常见的点云配准方法ICP&amp;NDT</strong></p><p>点云配准算法 求解R,t</p><p>icp、ndt</p><p>没有一个明确的最少点数要求，但为了确保ICP算法的鲁棒性和准确性，通常推荐使用尽可能多的点，同时保证点云的均匀分布和质量。</p><p>不涉及二维到三维，因此不需要内参</p><h2 id=三角测量空间前方交会-已知观察未知>三角测量（空间前方交会 已知观察未知）</h2><p><a href=https://baike.baidu.com/item/%E7%A9%BA%E9%97%B4%E5%89%8D%E6%96%B9%E4%BA%A4%E4%BC%9A target=_blank rel="noopener noreffer">https://baike.baidu.com/item/%E7%A9%BA%E9%97%B4%E5%89%8D%E6%96%B9%E4%BA%A4%E4%BC%9A</a></p><p>由<a href="https://baike.baidu.com/item/%E7%AB%8B%E4%BD%93%E5%83%8F%E5%AF%B9/0?fromModule=lemma_inlink" target=_blank rel="noopener noreffer">立体像对</a>左右两影像的内、<a href="https://baike.baidu.com/item/%E5%A4%96%E6%96%B9%E4%BD%8D%E5%85%83%E7%B4%A0/0?fromModule=lemma_inlink" target=_blank rel="noopener noreffer">外方位元素</a>和<a href="https://baike.baidu.com/item/%E5%90%8C%E5%90%8D%E5%83%8F%E7%82%B9/0?fromModule=lemma_inlink" target=_blank rel="noopener noreffer">同名像点</a>的影像坐标测量值来确定该点的物方空间坐标。</p><p><a href=https://gutsgwh1997.github.io/2020/03/31/%E5%A4%9A%E8%A7%86%E5%9B%BE%E4%B8%89%E8%A7%92%E5%8C%96/ target=_blank rel="noopener noreffer">https://gutsgwh1997.github.io/2020/03/31/%E5%A4%9A%E8%A7%86%E5%9B%BE%E4%B8%89%E8%A7%92%E5%8C%96/</a></p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2038.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2038.png, /posts/algorithm_knowledge_base/7_vslam/image%2038.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2038.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2038.png title=image.png width=785 height=455></p><p>已知夹角和基线（R和t）、内参矩阵以及特征点像素坐标p1、p2，求解深度s1、s2</p><p>s1 x1 = s2 Rx2 + t.</p><h2 id=orb-slam2>orb-slam2</h2><p>单目、双目、RGBD</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/algorithm_knowledge_base/7_vslam/image%2039.png data-srcset="/posts/algorithm_knowledge_base/7_vslam/image%2039.png, /posts/algorithm_knowledge_base/7_vslam/image%2039.png 1.5x, /posts/algorithm_knowledge_base/7_vslam/image%2039.png 2x" data-sizes=auto alt=/posts/algorithm_knowledge_base/7_vslam/image%2039.png title=image.png width=818 height=556></p><p>主线程 创建了<a href=https://github.com/gaoyichao/ORB_SLAM2/blob/master/include/System.h target=_blank rel="noopener noreffer">System</a>类型的对象，核心控制器，负责调度</p><p>四个并行子线程</p><p>轨迹追踪</p><p>局部建图</p><p>回环检测 全部完成后会开启全局BA线程</p><p>可视化稀疏地图</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2025-04-16</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/ data-title=视觉slam data-hashtags=3d,slam><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/ data-hashtag=3d><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/ data-title=视觉slam><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/ data-title=视觉slam><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://fjyu95.github.io/posts/algorithm_knowledge_base/7_vslam/ data-title=视觉slam><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/3d/>3d</a>,&nbsp;<a href=/tags/slam/>Slam</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/algorithm_knowledge_base/8_%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/ class=prev rel=prev title=三维重建><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>三维重建</a>
<a href=/posts/algorithm_knowledge_base/6_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ class=next rel=next title=深度学习>深度学习<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.145.0">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.3.0"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2020 - 2025</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://fjyu95.github.io/ target=_blank>fjyu95</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>